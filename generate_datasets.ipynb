{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7e12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#countries geojson source = https://datahub.io/core/geo-countries#data\n",
    "#states geojson source = https://public.opendatasoft.com/explore/dataset/us-state-boundaries/table/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "febf3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import geocoder\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from shapely.geometry import LineString, MultiPoint\n",
    "from perpetual_functions import rangeSummary\n",
    "from perpetual_functions import placeCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09dc2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ IN DATA, FORMAT, AND SAVE TO CORRECT PLACES\n",
    "log = pd.read_csv('lifelog_current.csv', header=None, usecols=[2,3,4,5], skip_blank_lines=True)\n",
    "log.dropna(how=\"all\", inplace=True)\n",
    "log.columns = ['date','home','region','city']\n",
    "log['date'] = pd.to_datetime(log['date']).dt.strftime('%Y-%m-%d')\n",
    "log['city'] = [(x[1][1]+', ' + x[1][0]) for x in pd.DataFrame(log[['region', 'city']]).iterrows()]\n",
    "log.to_csv('lifelog_current_clean.csv', index=False)\n",
    "log_dict = {x[0]:tuple(x[1]) for x in log.iterrows()}\n",
    "with open('formatted_website/data/current_clean_json.json', 'w') as out_file:\n",
    "    json.dump(log_dict, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "128e5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE CITY GEOJSON\n",
    "#generate counts for city and create dataframe\n",
    "city_counts = placeCounts('1997-06-01', 'city', log)\n",
    "del city_counts['n/a']\n",
    "city_count_list = list(map(lambda x: (x[0], x[1][0], x[1][1]), city_counts.items()))\n",
    "city_df = pd.DataFrame(city_count_list, columns=['city','days', 'prop'])\n",
    "\n",
    "#geocode\n",
    "longitude = []\n",
    "latitude = []\n",
    "\n",
    "for city in city_df['city']:\n",
    "    if 'Georgia' in city:\n",
    "        city = city.split(',')[0] + ', Georgia (' #because using Georgia(State), Georgia(Country)\n",
    "    result = geocoder.osm(city)\n",
    "    longitude.append(result.json['lng'])\n",
    "    latitude.append(result.json['lat'])\n",
    "city_df['longitude'] = longitude\n",
    "city_df['latitude'] = latitude\n",
    "city_gdf = gpd.GeoDataFrame(city_df, geometry=gpd.points_from_xy(x=city_df['longitude'], y=city_df['latitude']))\n",
    "city_gdf = city_gdf.drop('longitude',axis=1)\n",
    "city_gdf = city_gdf.drop('latitude',axis=1)\n",
    "\n",
    "city_gdf.to_file('for_mapbox/current_points.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fbddaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE REGION GEOJSON\n",
    "#send totals for each area to respective json files\n",
    "region_counts = placeCounts('1997-06-01', 'region', log)\n",
    "del region_counts['n/a']\n",
    "for i in ['region', 'city']:\n",
    "    with open('formatted_website/data/'+i+'_totals.json', 'w') as file:\n",
    "        json.dump(eval(i+'_counts'), file)\n",
    "        \n",
    "#prepare region data: stay data as well as polygons\n",
    "region_stay_df = pd.DataFrame([(x[0], x[1][0], x[1][1]) for x in region_counts.items()], \n",
    "                         columns = ['region', 'days', 'prop'])\n",
    "region_stay_df['cities'] = [{y[0].split(', ')[0]:y[1][0] for y in city_counts.items() if y[0].split(', ')[1] == x} \n",
    "                            for x in region_stay_df['region']]\n",
    "\n",
    "#read in polygon data\n",
    "countries = gpd.read_file('countries.geojson')\n",
    "countries = countries[['ADMIN', 'geometry']]\n",
    "countries.columns = ['name', 'geometry']\n",
    "states = gpd.read_file('us-state-boundaries.geojson')\n",
    "states = states[['name', 'geometry']]\n",
    "\n",
    "#resolve the name issues\n",
    "state_ga_idx = list(states['name']).index('Georgia')\n",
    "states.at[state_ga_idx, 'name'] = 'Georgia (State)'\n",
    "country_ga_idx = list(countries['name']).index('Georgia')\n",
    "countries.at[country_ga_idx, 'name'] = 'Georgia (Country)'\n",
    "country_mk_idx = list(countries['name']).index('Macedonia')\n",
    "countries.at[country_mk_idx, 'name'] = 'North Macedonia'\n",
    "country_rs_idx = list(countries['name']).index('Republic of Serbia')\n",
    "countries.at[country_rs_idx, 'name'] = 'Serbia'\n",
    "\n",
    "#get rid of us territories and us, to replace with us polygons\n",
    "duplicates = ['United States of America']\n",
    "for i in list(countries['name']):\n",
    "    for j in list(states['name']):\n",
    "        if i == j:\n",
    "            duplicates.append(i)\n",
    "countries_list = list(countries['name'])\n",
    "for dup in duplicates:\n",
    "    country_idx = countries_list.index(dup)\n",
    "    countries = countries.drop(country_idx)\n",
    "\n",
    "#combine countries, states, and personal stay data\n",
    "regions = countries.append(states)\n",
    "regions = regions.merge(region_stay_df, how='left', left_on='name', right_on='region')\n",
    "regions = regions.drop('region', axis=1)\n",
    "regions = regions.fillna(0)\n",
    "\n",
    "#used to check for region name issues\n",
    "for j in region_stay_df['region']:\n",
    "    if j not in list(regions['name']):\n",
    "        print('uh oh: '+j)\n",
    "        \n",
    "#simplify so mapbox works gud and send to file\n",
    "regions_out = regions\n",
    "regions_out['geometry'] = regions['geometry'].simplify(tolerance=0.01)\n",
    "regions_out.to_file('for_mapbox/current_regions.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8cdb0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE LINE DATA\n",
    "#keep only necessary columns and dates where there is a move\n",
    "line_log = log[['city', 'date']]\n",
    "line_log = line_log.values.tolist()\n",
    "key_days = [line_log[0]]\n",
    "for x in range(len(line_log)-2):\n",
    "    idx = x+1\n",
    "    if (line_log[idx][0] != line_log[idx-1][0]) or (line_log[idx][0] != line_log[idx+1][0]):\n",
    "        key_days.append(line_log[idx])\n",
    "key_days.append(line_log[-1])\n",
    "\n",
    "#calculate length of duration\n",
    "line_list = []\n",
    "for x in range(len(key_days)-1):\n",
    "    if key_days[x][0] != key_days[x+1][0]:\n",
    "        save_row = ((key_days[x][0], key_days[x+1][0]), \n",
    "                    (datetime.strptime(key_days[x][1],'%Y-%m-%d') - datetime.strptime(key_days[0][1],'%Y-%m-%d')).days, \n",
    "                    (key_days[x][1],key_days[x+1][1]))\n",
    "        line_list.append(save_row)\n",
    "        \n",
    "#so locations can be easily indexed\n",
    "city_df = city_df.set_index('city')\n",
    "\n",
    "#generate gdf\n",
    "line_gdf = gpd.GeoDataFrame([x[0] + (x[1],) + x[2] + \n",
    "                             (LineString([city_df.loc[x[0][0]]['geometry'],\n",
    "                                         city_df.loc[x[0][1]]['geometry']]),)\n",
    "                             for x in line_list], columns = ['start_loc', 'end_loc', 'time_int', 'start_date', \n",
    "                                                             'end_date', 'geometry'])\n",
    "line_gdf.to_file('for_mapbox/current_line.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f029a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE POINTS FOR EACH KEY DAY AND ALL CENTORIDS\n",
    "city_gdf = city_gdf.set_index('city')\n",
    "\n",
    "log_list = log[['date', 'city']].values.tolist()\n",
    "points_days = [(log_list[x][1], \n",
    "                (datetime.strptime(log_list[x][0],'%Y-%m-%d') - datetime.strptime(log_list[0][0],'%Y-%m-%d')).days, \n",
    "                city_gdf.loc[log_list[x][1]]['geometry'])\n",
    "              for x in range(len(log_list))]\n",
    "point_geoseries = [x[2] for x in points_days]#for centroids\n",
    "points_days = [points_days[0]] + [points_days[x] for x in range(1,len(points_days)-1) \\\n",
    "    if not(points_days[x][0] == points_days[x-1][0] and points_days[x][0] == points_days[x+1][0])] \\\n",
    "    + [points_days[-1]]\n",
    "\n",
    "#send key points to file\n",
    "points_days_gdf = gpd.GeoDataFrame(points_days, columns=['city', 'time_int', 'geometry'])\n",
    "points_days_gdf.to_file('for_mapbox/current_all_points.geojson', driver='GeoJSON')\n",
    "\n",
    "centroid_list = [point_geoseries[0]]+[MultiPoint(point_geoseries[0:x+2]).centroid for x in range(len(point_geoseries)-1)]\n",
    "centroid_gdf = gpd.GeoDataFrame(zip(log['date'], centroid_list), columns=['date', 'geometry'])\n",
    "centroid_gdf.to_file('for_mapbox/current_centroids.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb9c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE STAYS FOR PLACE BAR\n",
    "stay_log = log[['date','city']]\n",
    "compressed_list = []\n",
    "same_count = 0\n",
    "first_date = stay_log.loc[0]['date']\n",
    "last_date = ''\n",
    "current_city = stay_log.loc[0]['city']\n",
    "for row in stay_log.values.tolist():\n",
    "    if row[1] == current_city:\n",
    "        same_count += 1;\n",
    "        last_date = row[0]\n",
    "    else:\n",
    "        compressed_list.append((current_city, same_count, first_date, last_date))\n",
    "        current_city = row[1]\n",
    "        first_date = row[0]\n",
    "        last_date = row[0]\n",
    "        same_count = 1\n",
    "compressed_list.append((current_city, same_count, first_date, stay_log.values.tolist()[-1][0]))#add last row\n",
    "compressed_dict = {x: compressed_list[x] for x in range(len(compressed_list))}\n",
    "with open('formatted_website/data/current_stays.json', 'w') as out_file:\n",
    "    json.dump(compressed_dict, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d74caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
